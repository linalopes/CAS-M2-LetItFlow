{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization:\n",
    "Normalizing the audio samples to a uniform length of 18 seconds, by cropping longer files and padding shorter ones.\n",
    "\n",
    "**Consistency**: Having all audio files with the same length makes it easier for algorithms to process and compare them. It avoids issues where models need to handle variable-length inputs.\n",
    "\n",
    "**Alignment**: When performing operations like feature extraction (e.g., frequency analysis, zero-crossing rate), it's beneficial for the features to be extracted from audio clips of the same duration, ensuring that features like spectral centroid and dominant frequency are based on consistent timeframes.\n",
    "\n",
    "**Padding Shorter Files**: Padding shorter files to a fixed length ensures that you don't lose important information from shorter clips. The padding (often with zeros) won't affect the meaningful parts of the signal but will give you a consistent length.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combined_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report, accuracy_score\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Prepare the features (X) and the labels (y)\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcombined_df\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamplitude_max\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspectral_centroid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdominant_frequency\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzero_crossing_rate\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m      8\u001b[0m y \u001b[38;5;241m=\u001b[39m combined_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Encode the labels (short, medium, long) into numerical values\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'combined_df' is not defined"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import os\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "\n",
    "# Path to the audio folder\n",
    "audio_folder = '../dataset'\n",
    "output_folder = '../normalized_dataset'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Target duration for all audio files (18 seconds)\n",
    "target_duration = 18  # seconds\n",
    "\n",
    "# Sample rate for loading and saving audio files\n",
    "sample_rate = 22050  # Adjust based on your original sample rate\n",
    "\n",
    "# Function to normalize audio length to 18 seconds\n",
    "def normalize_audio_length(file_path, output_path, target_duration, sample_rate):\n",
    "    y, sr = librosa.load(file_path, sr=sample_rate)\n",
    "    \n",
    "    # Calculate the target length in samples\n",
    "    target_length = int(target_duration * sample_rate)\n",
    "    \n",
    "    if len(y) > target_length:\n",
    "        # Crop the audio if it's longer than 18 seconds\n",
    "        y = y[:target_length]\n",
    "    else:\n",
    "        # Pad the audio with zeros if it's shorter than 18 seconds\n",
    "        padding = target_length - len(y)\n",
    "        y = np.pad(y, (0, padding), 'constant')\n",
    "    \n",
    "    # Save the normalized audio to the output folder\n",
    "    sf.write(output_path, y, sample_rate)\n",
    "\n",
    "# Normalize all audio files in the dataset\n",
    "for filename in os.listdir(audio_folder):\n",
    "    if filename.endswith('.wav'):  # Adjust extension if necessary\n",
    "        file_path = os.path.join(audio_folder, filename)\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        normalize_audio_length(file_path, output_path, target_duration, sample_rate)\n",
    "\n",
    "print(\"All audio files have been normalized to 18 seconds.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aicp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
