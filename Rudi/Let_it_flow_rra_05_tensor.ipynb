{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import Necessary Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.15.0\n",
      "PyTorch version: 2.5.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"PyTorch version:\", torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/rrenoir/miniforge3/envs/tf-macos-env/lib/python39.zip', '/Users/rrenoir/miniforge3/envs/tf-macos-env/lib/python3.9', '/Users/rrenoir/miniforge3/envs/tf-macos-env/lib/python3.9/lib-dynload', '', '/Users/rrenoir/miniforge3/envs/tf-macos-env/lib/python3.9/site-packages', '/Users/rrenoir/miniforge3/envs/tf-macos-env/lib/python3.9/site-packages/setuptools/_vendor']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/rrenoir/miniforge3/envs/aicp/lib/python3.10/site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-macos==2.15.0 in /Users/rrenoir/miniforge3/envs/aicp/lib/python3.10/site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/rrenoir/miniforge3/envs/aicp/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/rrenoir/miniforge3/envs/aicp/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/rrenoir/miniforge3/envs/aicp/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/rrenoir/miniforge3/envs/aicp/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/rrenoir/miniforge3/envs/aicp/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/rrenoir/miniforge3/envs/aicp/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/rrenoir/miniforge3/envs/aicp/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /Users/rrenoir/miniforge3/envs/aicp/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Users/rrenoir/miniforge3/envs/aicp/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/rrenoir/miniforge3/envs/aicp/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/rrenoir/miniforge3/envs/aicp/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/rrenoir/miniforge3/envs/aicp/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (4.25.5)\n",
      "Requirement already satisfied: setuptools in /Users/rrenoir/miniforge3/envs/aicp/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (72.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/rrenoir/miniforge3/envs/aicp/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/rrenoir/miniforge3/envs/aicp/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/rrenoir/miniforge3/envs/aicp/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /Users/rrenoir/miniforge3/envs/aicp/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/rrenoir/miniforge3/envs/aicp/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/rrenoir/miniforge3/envs/aicp/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.66.1)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /Users/rrenoir/miniforge3/envs/aicp/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /Users/rrenoir/miniforge3/envs/aicp/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /Users/rrenoir/miniforge3/envs/aicp/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/rrenoir/miniforge3/envs/aicp/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.15.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/rrenoir/miniforge3/envs/aicp/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.35.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /Users/rrenoir/miniforge3/envs/aicp/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (1.2.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/rrenoir/miniforge3/envs/aicp/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/rrenoir/miniforge3/envs/aicp/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/rrenoir/miniforge3/envs/aicp/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/rrenoir/miniforge3/envs/aicp/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/rrenoir/miniforge3/envs/aicp/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/rrenoir/miniforge3/envs/aicp/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/rrenoir/miniforge3/envs/aicp/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/rrenoir/miniforge3/envs/aicp/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rrenoir/miniforge3/envs/aicp/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rrenoir/miniforge3/envs/aicp/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rrenoir/miniforge3/envs/aicp/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rrenoir/miniforge3/envs/aicp/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2024.7.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/rrenoir/miniforge3/envs/aicp/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/rrenoir/miniforge3/envs/aicp/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/rrenoir/miniforge3/envs/aicp/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.15.0\n",
      "PyTorch version: 2.5.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import tensorflow as tf\n",
    "\n",
    "# Verify TensorFlow and PyTorch installations\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"PyTorch version:\", torch.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Data Preprocessing (convert audio to spectrogram)\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, dataset_path, max_width=400):  # You can adjust max_width\n",
    "        self.dataset_path = dataset_path\n",
    "        self.file_list = [os.path.join(dataset_path, file) for file in os.listdir(dataset_path) if file.endswith('.wav')]\n",
    "        self.max_width = max_width\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        audio_path = self.file_list[idx]\n",
    "        audio, sr = librosa.load(audio_path, sr=16000)\n",
    "        # Convert audio to Mel-spectrogram\n",
    "        spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=128)\n",
    "        spectrogram = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "        # Normalize spectrogram\n",
    "        spectrogram = (spectrogram - spectrogram.min()) / (spectrogram.max() - spectrogram.min())\n",
    "        \n",
    "        # Check the width (time dimension) of the spectrogram\n",
    "        width = spectrogram.shape[1]\n",
    "        if width < self.max_width:\n",
    "            # Pad if the spectrogram is smaller than max_width\n",
    "            padding = self.max_width - width\n",
    "            spectrogram = F.pad(torch.tensor(spectrogram, dtype=torch.float32), (0, padding), \"constant\", 0)\n",
    "        else:\n",
    "            # Truncate if the spectrogram is larger than max_width\n",
    "            spectrogram = torch.tensor(spectrogram[:, :self.max_width], dtype=torch.float32)\n",
    "        \n",
    "        # Ensure the spectrogram has 4 dimensions: (1, channels, height, width)\n",
    "        spectrogram = spectrogram.unsqueeze(0)  # Add channel dimension\n",
    "\n",
    "        return spectrogram\n",
    "\n",
    "# Define path to your dataset folder\n",
    "dataset_path = '../dataset'\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = AudioDataset(dataset_path, max_width=400)  # Adjust max_width according to your needs\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: CNN-LSTM Model\n",
    "class CNN_LSTM(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN_LSTM, self).__init__()\n",
    "        # CNN layers\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(64, 128, batch_first=True)\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input shape: (batch_size, channels, height, width)\n",
    "        batch_size, channels, height, width = x.size()\n",
    "        \n",
    "        # CNN feature extraction\n",
    "        x = self.cnn(x)  # After CNN: (batch_size, 64, height, width)\n",
    "        \n",
    "        # Reshape for LSTM (batch_size, width, height * channels)\n",
    "        x = x.permute(0, 3, 1, 2)  # Change to (batch_size, width, channels, height)\n",
    "        x = x.reshape(batch_size, x.size(1), -1)  # Flatten to (batch_size, width, features)\n",
    "        \n",
    "        # LSTM processing\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        \n",
    "        # Take the output of the last time step\n",
    "        final_output = lstm_out[:, -1, :]\n",
    "        \n",
    "        # Fully connected layer for classification\n",
    "        out = self.fc(final_output)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m  \u001b[38;5;66;03m# Replace with actual number of classes (e.g., slow vs. fast pouring)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m model \u001b[38;5;241m=\u001b[39m CNN_LSTM(num_classes)\n\u001b[0;32m---> 27\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 14\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloader, epochs)\u001b[0m\n\u001b[1;32m     11\u001b[0m labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, num_classes, (spectrograms\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m),))  \u001b[38;5;66;03m# Dummy labels, replace with actual\u001b[39;00m\n\u001b[1;32m     13\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 14\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspectrograms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     16\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniforge3/envs/tf-macos-env/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf-macos-env/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[9], line 21\u001b[0m, in \u001b[0;36mCNN_LSTM.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# Input shape: (batch_size, channels, height, width)\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     batch_size, channels, height, width \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# CNN feature extraction\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcnn(x)  \u001b[38;5;66;03m# After CNN: (batch_size, 64, height, width)\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 3)"
     ]
    }
   ],
   "source": [
    "# Step 3: Training Loop\n",
    "def train_model(model, dataloader, epochs=10):\n",
    "    criterion = nn.CrossEntropyLoss()  # Use appropriate loss function for classification\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, spectrograms in enumerate(dataloader):\n",
    "            spectrograms = spectrograms.squeeze(1)  # Remove extra channel dim\n",
    "            labels = torch.randint(0, num_classes, (spectrograms.size(0),))  # Dummy labels, replace with actual\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(spectrograms)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i % 10 == 9:  # Print every 10 batches\n",
    "                print(f\"Epoch {epoch+1}, Batch {i+1}, Loss: {running_loss / 10}\")\n",
    "                running_loss = 0.0\n",
    "\n",
    "# Initialize and train the model\n",
    "num_classes = 2  # Replace with actual number of classes (e.g., slow vs. fast pouring)\n",
    "model = CNN_LSTM(num_classes)\n",
    "train_model(model, dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e08475e4f7e43ffb36df511ed93dac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting features:   0%|          | 0/5638 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vectors normalized shape: (5638, 416)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 22\u001b[0m\n\u001b[1;32m     17\u001b[0m train_features, val_features, train_labels, val_labels \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[1;32m     18\u001b[0m     feature_vectors_normalized, tempo_labels_normalized, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Create TensorFlow datasets\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_tf_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m create_tf_dataset(val_features, val_labels, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Cell 9: Define the Regression Model in TensorFlow\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 12\u001b[0m, in \u001b[0;36mcreate_tf_dataset\u001b[0;34m(features, labels, batch_size)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_tf_dataset\u001b[39m(features, labels, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m):\n\u001b[0;32m---> 12\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_tensor_slices((features, labels))\n\u001b[1;32m     13\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mshuffle(buffer_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(features))\u001b[38;5;241m.\u001b[39mbatch(batch_size)\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'data'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-macos-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
